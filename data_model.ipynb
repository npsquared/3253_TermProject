{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (28, 28, 1)\n",
    "layer_sizes = (128, 64)\n",
    "n_filters = (32, 64, 128)\n",
    "kernel_sizes = (7, 3, 3)\n",
    "pool_size = 2\n",
    "drop_prob = 0.5\n",
    "\n",
    "\n",
    "n_classes = 345   #output_dim/units is equal to the number of image classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([Convolution2D(filters = 32,\n",
    "                        kernel_size = (3,3),\n",
    "                        activation = \"relu\",\n",
    "                        input_shape = img_size),\n",
    "                    Convolution2D(filters = 32,\n",
    "                        kernel_size = (3,3),\n",
    "                        activation = \"relu\"),\n",
    "                    MaxPooling2D(pool_size=(2,2)),\n",
    "                    Dropout(.20),\n",
    "                    Convolution2D(filters = 64,\n",
    "                        kernel_size = (3,3),\n",
    "                        activation = \"relu\"),\n",
    "                    Convolution2D(filters = 64,\n",
    "                        kernel_size = (3,3),\n",
    "                        activation = \"relu\"),\n",
    "                    MaxPooling2D(pool_size=(2,2)),\n",
    "                    Dropout(.1),\n",
    "                    Flatten(),\n",
    "                    Dense(256, activation=\"relu\"),\n",
    "                    Dense(n_classes, activation=\"softmax\") \n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 345)               88665     \n",
      "=================================================================\n",
      "Total params: 416,057\n",
      "Trainable params: 416,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating additional training and test data using ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"datasets/data/train_set/\"\n",
    "test_path = \"datasets/data/test_set/\"\n",
    "\n",
    "data_file_path = \"datasets/data/numpy_bitmap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2760000 images belonging to 345 classes.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(28, 28),\n",
    "        color_mode=\"grayscale\",\n",
    "        batch_size=128,\n",
    "        class_mode='categorical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 690000 images belonging to 345 classes.\n",
      "Wall time: 25.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=(28, 28),\n",
    "        color_mode=\"grayscale\",\n",
    "        batch_size=128,\n",
    "        class_mode='categorical') \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"nadam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_cb = ModelCheckpoint(\"conv_doodle_model.h5\",\n",
    "                          save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 6378/12000 [==============>...............] - ETA: 26:53 - loss: 3.8946 - accuracy: 0.1893"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit_generator(\n",
    "            training_set,\n",
    "            steps_per_epoch=12000,\n",
    "            epochs=20,\n",
    "            validation_data=test_set,\n",
    "            validation_steps=3000, \n",
    "            callbacks=[save_cb])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_new.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model_new.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution layer 1\n",
    "#model.add(Convolution2D(filters = 32,\n",
    "#                        kernel_size = (3,3),\n",
    "#                        activation = \"relu\",\n",
    "#                        input_shape = (28,28,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution layer 2\n",
    "#model.add(Convolution2D(filters = 32,\n",
    "#                        kernel_size = (3,3),\n",
    "#                        activation = \"relu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxpooling layer 1\n",
    "#model.add(MaxPooling2D(pool_size=(2,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deactivating some elements to avoid overfitting\n",
    "#model.add(Dropout(.20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution layer 3\n",
    "#model.add(Convolution2D(filters = 64,\n",
    "#                        kernel_size = (3,3),\n",
    "#                        activation = \"relu\"))\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution layer 4\n",
    "#model.add(Convolution2D(filters = 64,\n",
    "#                        kernel_size = (3,3),\n",
    "#                        activation = \"relu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxpooling layer 2\n",
    "#model.add(MaxPooling2D(pool_size=(2,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deactivating some elements\n",
    "#model.add(Dropout(.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattening layer\n",
    "#model.add(Flatten())\n",
    "\n",
    "# fully connected layer\n",
    "#model.add(Dense(256, activation=\"relu\"))\n",
    "#model.add(Dense(output_dim=5, activation=\"softmax\"))  #output_dim is the number of classes used for classification\n",
    "                                                      # i.e the image categories  \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
